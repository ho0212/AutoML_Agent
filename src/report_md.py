from __future__ import annotations
from tabulate import tabulate
import os, json

def _rel_for_report(img_path: str, report_dir: str = "reports") -> str:
    # path relative to the folder where the .md is written
    rel = os.path.relpath(img_path, start=report_dir)
    return rel.replace("\\", "/")  # normalize for markdown

def make_markdown(dataset_name: str, problem: str, overview: dict, plot_paths: list[str], 
                  model_name: str, metrics: dict, narrative: str | None = None) -> str:
    lines = [] #content
    lines += [f"# AutoML Agent Report - {dataset_name}"]

    lines += ["## Overview",
              f"- Problem Type: **{problem}**",
              f"- Rows: {overview['n_rows']}, Cols: {overview['n_cols']}",
              f"- Target distribution (top): {str(dict(list(overview.get('target_value_counts', {}).items())[:5]))}",
              ""
              ]
    lines += ["## Missingness (top 10)",
              "```",
              json.dumps({k:v for k,v in sorted(overview['missing_percentage'].items(), key=lambda kv: kv[1], reverse=True)[:10]}, indent=2),
              "```",
              ""]
    if plot_paths:
        lines += ["## EDA Plots", ""]
        for p in plot_paths[:12]:
            rel = _rel_for_report(p, report_dir="reports")
            lines += [f"![{os.path.basename(p)}]({rel})"]
        lines += [""]
    
    lines += ["## Model & Metrics",
              f"- Selected model: **{model_name}**",
              "",
              "```\n" + tabulate([[k, v] for k,v in metrics.items()], headers=["metric","value"]) + "\n```",
              ""]
    
    if narrative:
        lines += ["## Narrative", narrative.strip(), ""]

    lines += ["## Notes", "- Generated by agent. Code-driven EDA & modeling; narrative by LLM.", ""]
    return "\n".join(lines)